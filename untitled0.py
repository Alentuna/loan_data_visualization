# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nkEVVoYIedZmUHD7ZHMOXHG75i4n0dbw
"""

https://colab.research.google.com/drive/1nkEVVoYIedZmUHD7ZHMOXHG75i4n0dbw#scrollTo=_joxpjNc6wUW

# Commented out IPython magic to ensure Python compatibility.
# import important libraries

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline
sns.set_theme(style = "darkgrid")

#data represents the traing data csv file
data = pd.read_csv("loan_datag.csv")
data.head()

rows, columns = data.shape
print('Rows:', rows)
print('Columns:', columns)

#Now we check the data types and other information.

data.info()

#Let us check if there are any missing values in the data.

data.isnull().sum()

"""Handling the  missing values in the data set by using pridictive imputation"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
import pandas as pd
import numpy as np

from sklearn.preprocessing import LabelEncoder


label_encoder = LabelEncoder()

# Encode the categorical target variable
data['Gender_encoded'] = label_encoder.fit_transform(data['Gender'])
data['Self_Employed_encoded'] = label_encoder.fit_transform(data['Self_Employed'])
data['Loan_Amount_Term_encoded'] = label_encoder.fit_transform(data['Loan_Amount_Term'])
data['Credit_History_encoded'] = label_encoder.fit_transform(data['Credit_History'])
data['Dependents_encoded'] = label_encoder.fit_transform(data['Dependents'])

data.head()

data.columns

"""Removing the columns with string value"""

#First, we start with the analysis of numerical data.

data.describe()

#Now, we check the data distribution.

data.hist( figsize = (22, 20) )
plt.show()

data["Loan_Status"].value_counts()

#Now, we plot the correlation plot.

fig, ax = plt.subplots( figsize = (12,8) )
corr_matrix = data.corr()
corr_heatmap = sns.heatmap( corr_matrix, cmap = "flare", annot=True, ax=ax, annot_kws={"size": 14})
plt.show()

def categorical_valcount_hist(feature):
    print(data[feature].value_counts())
    fig, ax = plt.subplots( figsize = (6,6) )
    sns.countplot(x=feature, ax=ax, data=data)
    plt.show()

categorical_valcount_hist("Married")

categorical_valcount_hist("Education")

categorical_valcount_hist("Self_Employed")

categorical_valcount_hist("Property_Area")

"""Dropping the cloums with string

"""

columns_to_drop = ['Dependents', 'Gender','Self_Employed','Credit_History','Loan_Amount_Term']

data.drop(columns=columns_to_drop, inplace=True)

print(data)

data.head()

data['Married_encoded'] = label_encoder.fit_transform(data['Married'])
data['Education_encoaded'] = label_encoder.fit_transform(data['Education'])
data['Property_Area_encoaded'] = label_encoder.fit_transform(data['Property_Area'])
data['Loan_Status_flag'] = label_encoder.fit_transform(data['Loan_Status'])
data['LoanID_encoded'] = label_encoder.fit_transform(data['Loan_ID'])

data.head()

columns_to_drop = ['Married', 'Education','Property_Area','Loan_Status','Loan_ID']

data.drop(columns=columns_to_drop, inplace=True)

print(data)

data.head()

"""Identify missing value columns and handling it"""

from sklearn.linear_model import LinearRegression


target_columns_with_missing_values = ['Self_Employed_encoded', 'Loan_Amount_Term_encoded', 'Credit_History_encoded','Dependents_encoded','Dependents_encoded','Gender_encoded']

# Iterate over each target column
for target_column in target_columns_with_missing_values:
    # Split data into complete cases and missing values for the current target column
    complete_cases = data.dropna(subset=[target_column])
    missing_values = data[data[target_column].isnull()]

    # Split complete cases into features and target for the current target column
    X_train = complete_cases.drop(target_columns_with_missing_values, axis=1)  # Features without missing values
    y_train = complete_cases[target_column]  # Target variable with missing values

    # Train a predictive model (Linear Regression in this case)
    model = LinearRegression()
    model.fit(X_train, y_train)

    # Predict missing values using the trained model for the current target column
    X_missing = missing_values.drop(target_columns_with_missing_values, axis=1)  # Features without missing values
    missing_values[target_column + '_predicted'] = model.predict(X_missing)

    # Impute missing values in the original dataset for the current target column
    data.loc[missing_values.index, target_column] = missing_values[target_column + '_predicted']

print(data)

#Let us check if there are any missing values in the data.

data.isnull().sum()

"""# New Section"""